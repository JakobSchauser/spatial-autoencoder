"""GAT-based point cloud autoencoder.

This module defines a graph neural network autoencoder for point clouds
using Graph Attention (GATConv) layers from PyTorch Geometric.

Each point in the cloud is treated as a node; edges are produced externally
via k-NN (or any other) graph construction and passed in as `edge_index`.

Encoder: Stack of GATConv layers producing a latent per-node embedding.
Decoder: Per-node MLP mapping latent embeddings back to reconstructed
         point (e.g. XYZ) coordinates.

Returned latent representation can be either the per-node latent (z) or
an optional pooled global embedding (not currently used inside forward,
but `global_mean_pool` helper is provided for future extensions).

Author: Generated by GitHub Copilot agent.
"""
from __future__ import annotations

from typing import List, Sequence, Optional

import torch
from torch import nn
import torch.nn.functional as F

try:
    from torch_geometric.nn import GATConv, global_mean_pool  # type: ignore
except ImportError as e:  # pragma: no cover - informative error
    raise ImportError(
        "torch_geometric is required. Install it following instructions at "
        "https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html"
    ) from e


class MLP(nn.Module):
    """Simple MLP used for decoding per-node latent features."""

    def __init__(self, dims: Sequence[int], activation: str = "elu", dropout: float = 0.0):
        super().__init__()
        layers: List[nn.Module] = []
        act_layer: nn.Module
        for i in range(len(dims) - 1):
            layers.append(nn.Linear(dims[i], dims[i + 1]))
            if i < len(dims) - 2:  # hidden layer
                if activation == "relu":
                    act_layer = nn.ReLU()
                elif activation == "gelu":
                    act_layer = nn.GELU()
                else:
                    act_layer = nn.ELU()
                layers.append(act_layer)
                if dropout > 0:
                    layers.append(nn.Dropout(dropout))
        self.net = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:  # noqa: D401
        return self.net(x)


class GATPointCloudAutoencoder(nn.Module):
    """Graph Attention Network Autoencoder for point clouds.

    Parameters
    ----------
    in_channels: int
        Input feature dimension (e.g. 3 for XYZ coordinates).
    hidden_dims: Sequence[int]
        Hidden dimensions for successive GATConv layers (excluding latent_dim).
    latent_dim: int
        Dimension of the latent per-node embedding produced by the encoder.
    heads: int
        Number of attention heads per GAT layer (except last which sets `concat=False`).
    dropout: float
        Dropout applied after attention layers.
    decode_hidden_dims: Optional[Sequence[int]]
        Hidden dimensions for the per-node decoding MLP (latent_dim -> ... -> in_channels).
    activation: str
        Activation name for GAT layers (elu|relu|gelu). Default: elu.
    """

    def __init__(
        self,
        in_channels: int = 3,
        hidden_dims: Sequence[int] = (64, 128),
    latent_dim: int = 64,
        heads: int = 4,
        dropout: float = 0.1,
        decode_hidden_dims: Optional[Sequence[int]] = None,
        activation: str = "elu",
    ) -> None:
        super().__init__()
        self.in_channels = in_channels
        self.hidden_dims = list(hidden_dims)
        self.latent_dim = latent_dim
        self.dropout = dropout
        self.heads = heads
        self.activation_name = activation

        dims_all = [in_channels] + list(hidden_dims)
        convs: List[nn.Module] = []
        act_layer: nn.Module
        for i in range(len(dims_all) - 1):
            in_c = dims_all[i]
            out_c = dims_all[i + 1]
            convs.append(GATConv(in_c, out_c // heads, heads=heads, dropout=dropout, concat=True))
        # final conv to latent_dim (no concat)
        last_in = dims_all[-1]
        convs.append(GATConv(last_in, latent_dim, heads=1, dropout=dropout, concat=False))
        self.convs = nn.ModuleList(convs)

        if activation == "relu":
            self.act = nn.ReLU()
        elif activation == "gelu":
            self.act = nn.GELU()
        else:
            self.act = nn.ELU()

        if decode_hidden_dims is None:
            decode_hidden_dims = [latent_dim // 2]
        self.decoder = MLP([latent_dim] + list(decode_hidden_dims) + [in_channels], activation=activation, dropout=dropout)

        self.reset_parameters()

    def reset_parameters(self) -> None:
        # GATConv exposes reset_parameters; call explicitly for clarity.
        for module in self.convs:
            if isinstance(module, GATConv):
                module.reset_parameters()
        for mod in self.decoder.modules():
            if isinstance(mod, nn.Linear):
                nn.init.xavier_uniform_(mod.weight)
                if mod.bias is not None:
                    nn.init.zeros_(mod.bias)

    def encode(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            if i < len(self.convs) - 1:  # no activation on final latent layer
                x = self.act(x)
                if self.dropout > 0:
                    x = F.dropout(x, p=self.dropout, training=self.training)
        return x  # latent per-node

    def decode(self, z: torch.Tensor) -> torch.Tensor:
        return self.decoder(z)

    def forward(self, x: torch.Tensor, edge_index: torch.Tensor):  # noqa: D401
        z = self.encode(x, edge_index)
        recon = self.decode(z)
        return recon, z

    @staticmethod
    def pooled_latent(z: torch.Tensor, batch: Optional[torch.Tensor]) -> torch.Tensor:
        if batch is None:
            # treat everything as one graph
            return z.mean(dim=0, keepdim=True)
        return global_mean_pool(z, batch)


def chamfer_distance(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:
    """Compute a simple (squared) Chamfer distance between two point sets.

    Notes
    -----
    - Complexity O(N^2); suitable for moderate N (<= 2048). For large point
      clouds consider libraries like PyTorch3D or Kaolin.
    - Assumes a.shape == b.shape == (N, d).
    """
    if a.ndim != 2 or b.ndim != 2:
        raise ValueError("Inputs must be (N,d) tensors")
    if a.shape != b.shape:
        raise ValueError("Point sets must have same shape")
    # (N, N)
    diff = a.unsqueeze(1) - b.unsqueeze(0)
    dist2 = (diff * diff).sum(-1)
    d1 = dist2.min(dim=1)[0]
    d2 = dist2.min(dim=0)[0]
    return d1.mean() + d2.mean()


__all__ = [
    "GATPointCloudAutoencoder",
    "chamfer_distance",
]
